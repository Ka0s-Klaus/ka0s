name: Ka0s BigQuery Query Export

on:
  workflow_dispatch:
    inputs:
      Ka0s-Clouder:
        description: 'Select your Ka0s Cloud Provider'
        required: true
        type: choice
        options:
          - GCP
          - AWS
          - OCI
      Ka0s-Query:
        description: 'Specify the query file, if left blank all queries in /bq/queries will be executed. Do not add extension. * execute all finops query'
        default: ''
        required: true
      

env:
  KAOS_CODE: ${{ github.run_id }}
  KAOS_REF: ${{ github.ref }}
  KAOS_MODULE: "[Ka0S] Ka0s BigQuery Operations"
  KAOS_BIGQUERY_CONFIG: "core/config/bigqueryconfig.json"
  KAOS_BIGQUERY_COST: "core/scripts/bq_cost_summary.py"
  KAOS_PATH_QUERY: "core/results/bq/queries/"
  KAOS_PATH_OUTPUT: "core/outputs/bq/"
  KAOS_PATH_RESULT: "core/results/bq/results/"
  KAOS_PATH_RESULT_WEB: "core/outputs/bq/results/"
  KAOS_OUTPUT_EXECUTION: "core/outputs/e/"
  QUERY_FILE: "core/results/bq/queries/${{ inputs.Ka0s-Query }}.sql"
  KAOS_REF_BRANCH: "master"
  OUTPUT_FILE: 'query_results_$(date +"%Y%m%d_%H%M%S").json'

jobs:
  job-core:
    runs-on: self-hosted
 
    steps:
    - id: checkout
      name: Checkout code
      uses: actions/checkout@v4
      with:
          fetch-depth: 0
          token: ${{ secrets.KAOS_REPO_TOKEN }}
    - id: auth
      name: Google Auth
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.KAOS_GCP_SA_KEY }}
        project_id: ${{ secrets.KAOS_GCP_PROJECT_ID }}
    - id: setup-gcloud
      name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@v2
      with:
        version: 'latest'
        service_account_key: ${{ secrets.KAOS_GCP_SA_KEY }}
        project_id: ${{ secrets.KAOS_GCP_PROJECT_ID }}

    - name: Load BigQuery configuration
      id: config
      run: |
        CONFIG=$(jq -r ".${{ inputs.Ka0s-Clouder }}" ${{ env.KAOS_BIGQUERY_CONFIG }})
        echo "organization=$(echo $CONFIG | jq -r '.organization')" >> $GITHUB_OUTPUT
        echo "dataset=$(echo $CONFIG | jq -r '.datasheet')" >> $GITHUB_OUTPUT
        echo "bigquery_table=$(echo $CONFIG | jq -r '.table')" >> $GITHUB_OUTPUT

    - name: Estimate query execution
      if: ${{ inputs.Ka0s-Query != '*' }}
      run: |
        QUERY=$(sed -e "s/__ORGANIZATION__/${{ steps.config.outputs.organization }}/g" \
                   -e "s/__DATASET__/${{ steps.config.outputs.dataset }}/g" \
                   -e "s/__TABLE__/${{ steps.config.outputs.bigquery_table }}/g" \
                   ${{ env.QUERY_FILE }})
        echo "=== QUERY ESTIMATION ==="
        echo "Query file: ${{ env.QUERY_FILE }}"
        echo "Query to execute:"
        echo "$QUERY"
        echo ""
        
        # Get query estimation
        ESTIMATION=$(bq query --dry_run --use_legacy_sql=false --max_rows=0 "$QUERY" )
        
        # Extract validation message and bytes processed
        VALIDATION_MSG=$(echo "$ESTIMATION" | awk -F'.' '{print $1}')
        BYTES=$(echo "$ESTIMATION" | grep -oP 'process \K[0-9]+')
        
        # Calculate TB and cost ($5 per TB)
        TB=$(echo "scale=4; $BYTES / (1024^4)" | bc)
        COST=$(echo "scale=4; $TB * 5" | bc)
        
        echo "Validation message: $VALIDATION_MSG"
        printf "Estimated bytes to process: ~%.2f\n" "$BYTES"
        printf "Estimated TB to process: ~%.2f TB\n" "$TB"
        printf "Estimated cost: \$%.2f USD (at \$5 per TB)\n" "$COST"
        echo "=== QUERY ESTIMATION ==="

    - name: Process all queries
      if: ${{ inputs.Ka0s-Query == '*' }}
      env:
          GH_TOKEN: ${{ secrets.KAOS_REPO_TOKEN }}
      run: |
        for QUERY_FILE in ${{ env.KAOS_PATH_QUERY }}*.sql; do
          QUERY_NAME=$(basename "$QUERY_FILE" .sql)
          echo "Processing query: $QUERY_NAME"
          
          # Estimate query execution
          QUERY=$(sed -e "s/__ORGANIZATION__/${{ steps.config.outputs.organization }}/g" \
                     -e "s/__DATASET__/${{ steps.config.outputs.dataset }}/g" \
                     -e "s/__TABLE__/${{ steps.config.outputs.bigquery_table }}/g" \
                     "$QUERY_FILE")
          
          echo "=== QUERY ESTIMATION ==="
          echo "Query file: $QUERY_FILE"
          echo "Query to execute:"
          echo "$QUERY"
          echo ""
          
          ESTIMATION=$(bq query --dry_run --use_legacy_sql=false --max_rows=0 "$QUERY")
          VALIDATION_MSG=$(echo "$ESTIMATION" | awk -F'.' '{print $1}')
          BYTES=$(echo "$ESTIMATION" | grep -oP 'process \K[0-9]+')
          TB=$(echo "scale=4; $BYTES / (1024^4)" | bc)
          COST=$(echo "scale=4; $TB * 5" | bc)
          
          echo "Validation message: $VALIDATION_MSG"
          printf "Estimated bytes to process: ~%.2f\n" "$BYTES"
          printf "Estimated TB to process: ~%.2f TB\n" "$TB"
          printf "Estimated cost: \$%.2f USD (at \$5 per TB)\n" "$COST"
          echo "=== QUERY ESTIMATION ==="
          
          # Execute the query
          echo "Executing query: $QUERY_NAME"
          bq query --format=prettyjson --use_legacy_sql=false --max_rows=400000 "$QUERY" | \
            tee "${{ env.KAOS_PATH_RESULT }}${{ env.KAOS_CODE }}_${QUERY_NAME}_${{ env.OUTPUT_FILE }}" \
                "${{ env.KAOS_PATH_RESULT_WEB }}${QUERY_NAME}_query_results.json"
          # Time Sleep
          i=5
          while ((i > 0)); do
            echo -ne "Tiempo restante antes de la próxima consulta: $i segundos\r"
            sleep 1
            ((i--))
          done
          echo -e "\nTiempo de espera completo"
        done
        echo "All queries processed successfully and creating graphs"
        gh workflow run create_graphs.yml --ref ${{ env.KAOS_REF_BRANCH }}
        
    - name: Run BigQuery query and export to JSON
      if: ${{ inputs.Ka0s-Query != '*' }}
      run: |
        # Replace placeholders in the SQL file
        QUERY=$(sed -e "s/__ORGANIZATION__/${{ steps.config.outputs.organization }}/g" \
                   -e "s/__DATASET__/${{ steps.config.outputs.dataset }}/g" \
                   -e "s/__TABLE__/${{ steps.config.outputs.bigquery_table }}/g" \
                   ${{ env.QUERY_FILE }})
        
        echo "Executing query:"
        echo "$QUERY"
        
        # Estimación de filas resultantes
        ROW_COUNT=$(bq query --dry_run --use_legacy_sql=false --format=json "$QUERY" | jq -r '.numDmlAffectedRows // .numRows // 0')
        #cho "Número estimado de filas: $ROW_COUNT"
        
        # Ejecución real de la consulta en JSON
        bq query --format=prettyjson --use_legacy_sql=false --max_rows=400000 "$QUERY" | tee ${{ env.KAOS_PATH_RESULT }}${{ env.KAOS_CODE }}_${{ inputs.Ka0s-Query }}_${{ env.OUTPUT_FILE }} ${{ env.KAOS_PATH_RESULT_WEB }}${{ inputs.Ka0s-Query }}'_query_results.json'

    - name: Upload results
      run: |
        echo "Uploading bigquery result files to the repository..."
        git config --global user.name "${{ secrets.KAOS_BOT_NAME }}"
        git config --global user.email "${{ secrets.KAOS_BOT_EMAIL }}"
        git pull
        git add ${{ env.KAOS_PATH_RESULT }}*
        git add ${{ env.KAOS_PATH_RESULT_WEB }}${{ inputs.Ka0s-Query }}'_query_results.json'
        git commit -m "[Ka0S] Uploading resume query result files to the repository..."
        git push

  handle-success:
      runs-on: self-hosted
      needs: [job-core]
      if: ${{ success() }}
      steps:
        - id: repo
          name: Checkout code
          if: ${{ always() }}
          uses: actions/checkout@v4
          with:
            fetch-depth: 0
            token: ${{ secrets.KAOS_REPO_TOKEN }}
        - id: handle-success-execution
          name: Run BigQuery Cost Analysis
          run: |
            echo "Handle Success please check ${{ env.KAOS_CODE }}"
            # python3 "${{ env.KAOS_BIGQUERY_COST }}" "${{ env.KAOS_OUTPUT_EXECUTION }}" "core/results/bq/bq_cost_summary.csv"
            # git config --global user.name "${{ secrets.KAOS_BOT_NAME }}"
            # git config --global user.email "${{ secrets.KAOS_BOT_EMAIL }}"
            # git pull
            # git add core/results/bq/bq_cost_summary.csv
            # git commit -m "[Ka0S] Update BigQuery cost summary and web data ..."
            # git push
        - id: end-handle
          name: Finaliza el workflow
          run: |
            echo "Handle Success please check ${{ env.KAOS_CODE }}"
  
  handle_failure:
      runs-on: self-hosted
      needs: [job-core, handle-success]
      if: ${{ failure() }} 
      steps:
        - id: repo
          name: Checkout code
          if: ${{ always() }}
          uses: actions/checkout@v4
          with:
            fetch-depth: 0
            token: ${{ secrets.KAOS_REPO_TOKEN }}
        - id: end-handle
          name: Finaliza el workflow
          run: |
            echo "Handle Failure please check ${{ env.KAOS_CODE }}"
  
  end-workflow:
      runs-on: self-hosted
      needs: [job-core, handle-success, handle_failure]
      if: ${{ always() && !contains(github.event.head_commit.message, '[Ka0S] ') }} 
      env:
          GH_TOKEN: ${{ secrets.KAOS_REPO_TOKEN }}
      steps:
        - id: repo
          name: Checkout code
          if: ${{ always() }}
          uses: actions/checkout@v4
          with:
            fetch-depth: 0
            token: ${{ secrets.KAOS_REPO_TOKEN }}
        - id: end-process
          name: Finaliza el workflow
          run: |
            echo "End process"
            echo "Se finaliza Ka0s ${{ env.KAOS_CODE }}"
            gh workflow run inspector.yml --ref ${{ env.KAOS_REF_BRANCH }} -f kaos-issue-id= -f kaos-workflow-id="${{ env.KAOS_CODE }}" -f kaos-user-start=""
