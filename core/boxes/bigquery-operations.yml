name: Ka0s BigQuery Operations
on:
  workflow_dispatch:
permissions:
  contents: write
  actions: write
env:
  PROJECT_ID: ${{ secrets.KAOS_GCP_PROJECT_ID }}
  ORGANIZATION_ID: ${{ secrets.KAOS_GCP_ORGANIZATION_ID }}
  KAOS_CODE: ${{ github.run_id }}
  KAOS_REF: ${{ github.ref }}
  KAOS_MODULE: "[Ka0S] Ka0s BigQuery Operations"
  KAOS_PATH_OUTPUT: "core/outputs/bq/"
  KAOS_PATH_RESULT: "core/results/bq/datasets/"
  KAOS_REF_BRANCH: "master"
jobs:
  job-core:
    runs-on: self-hosted
 
    steps:
    - id: checkout
      name: Checkout code
      uses: actions/checkout@v4
      with:
          fetch-depth: 0
          token: ${{ secrets.KAOS_REPO_TOKEN }}
    - id: auth
      name: Google Auth
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.KAOS_GCP_SA_KEY }}
        project_id: ${{ secrets.KAOS_GCP_PROJECT_ID }}
    - id: setup-gcloud
      name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@v2
      with:
        version: 'latest'
        service_account_key: ${{ secrets.KAOS_GCP_SA_KEY }}
        project_id: ${{ secrets.KAOS_GCP_PROJECT_ID }}
    - id: verify-bigquery-policy
      name: Verify BigQuery Policy Access    
      run: |
        # Verify organization policy access
        echo "Verifying organization policy access..."
        # if gcloud organizations get-iam-policy ${{ secrets.KAOS_GCP_ORGANIZATION_ID }} --format=json > /dev/null 2>&1; then
        #   echo "Organization policy access: OK"
        # else
        #   echo "Organization policy access: FAILED"
        #   # Get service policy account permissions when organization access fails
        #   gcloud projects get-iam-policy ${{ secrets.KAOS_GCP_PROJECT_ID }} --format=json > service_account_permissions.json
        #   #exit 1
        # fi
    - id: verify-bigquery-access
      name: Verify BigQuery Access    
      run: |
        # Verify BigQuery access
        echo "Verifying BigQuery access..."
        if bq ls --project_id=${{ secrets.KAOS_GCP_PROJECT_ID }} > /dev/null 2>&1; then
          echo "BigQuery access: OK"
        else
          echo "BigQuery access: FAILED"
          # Get service account permissions when BigQuery access fails
        fi
    - id: extract-bigquery-datasets
      name: Extracting BigQuery Structure DataSets    
      run: |
        # Create output directory
        mkdir -p ${{ env.KAOS_PATH_OUTPUT }}
        
        # Extracting the structure of BigQuery tables
        echo "Extracting the structure of BigQuery tables..."
        
        # Try with bq command first
        if bq ls --project_id=${{ secrets.KAOS_GCP_PROJECT_ID }} --format=json > ${{ env.KAOS_PATH_OUTPUT }}datasets.json 2>&1; then
          echo "Extract BigQuery Structure: OK"
        else
          echo "First attempt failed, trying alternative approach..."
          
          # Try with gcloud command as fallback
          if gcloud bigquery datasets list --project=${{ secrets.KAOS_GCP_PROJECT_ID }} --format=json > ${{ env.KAOS_PATH_OUTPUT }}datasets.json 2>&1; then
            echo "Extract BigQuery Structure with gcloud: OK"
          else
            echo "Extract BigQuery Structure: FAILED"
            echo "Checking service account permissions..."
            gcloud projects get-iam-policy ${{ secrets.KAOS_GCP_PROJECT_ID }} --format=json > ${{ env.KAOS_PATH_OUTPUT }}service_account_permissions.json 2>&1
            exit 1
          fi
        fi  
    - id: extract-dataset-structures
      name: Extract Structure of Each Dataset
      if: success()
      run: |
        # Create directory for dataset structures if it doesn't exist
        mkdir -p core/outputs/bq/datasets
        
        # Check if datasets.json exists and has content
        if [ ! -s ${{ env.KAOS_PATH_OUTPUT }}datasets.json ]; then
          echo "No datasets found or datasets.json is empty"
          exit 0
        fi
        
        # Get list of datasets
        echo "Extracting structure of each dataset..."
        
        # Extract datasets from the JSON file - handle both formats
        datasets=$(cat ${{ env.KAOS_PATH_OUTPUT }}datasets.json | jq -r '.[] | if has("datasetReference") then .datasetReference.datasetId else .id end')
        
        if [ -z "$datasets" ]; then
          echo "No datasets found in the JSON output"
          exit 0
        fi
        
        # Loop through each dataset and extract its structure
        for dataset in $datasets; do
          echo "Processing dataset: $dataset"
          
          # Create directory for this dataset
          mkdir -p ${{ env.KAOS_PATH_RESULT }}$dataset
          
          # Extract dataset structure and save to JSON file
          if bq show --format=json --project_id=${{ secrets.KAOS_GCP_PROJECT_ID }} $dataset > ${{ env.KAOS_PATH_RESULT }}${dataset}/${dataset}_structure.json 2>&1; then
            echo "  - Structure extracted successfully"
            # Get tables in the dataset
            if bq ls --format=json --project_id=${{ secrets.KAOS_GCP_PROJECT_ID }} $dataset > ${{ env.KAOS_PATH_RESULT }}${dataset}/${dataset}_tables.json; then
              # Extract structure of each table in the dataset
              echo "Extract structure of each table in the dataset in ${{ env.KAOS_PATH_RESULT }}${dataset}/${dataset}_tables.json"
              tables=$(cat ${{ env.KAOS_PATH_RESULT }}${dataset}/${dataset}_tables.json | jq -r '.[] | if has("tableReference") then .tableReference.tableId else .id end')
              
              for table in $tables; do
                echo "    - Extracting schema for table: $table"
                bq show --schema --format=json --project_id=${{ secrets.KAOS_GCP_PROJECT_ID }} $dataset.$table > ${{ env.KAOS_PATH_RESULT }}$dataset/${table}_schema.json 2>&1
              done
            else
              echo "  - Failed to list tables for dataset: $dataset"
            fi
          else
            echo "  - Failed to extract structure for dataset: $dataset"
            # Try alternative approach with gcloud
            gcloud bigquery tables list --dataset=$dataset --project=${{ secrets.KAOS_GCP_PROJECT_ID }} --format=json > ${{ env.KAOS_PATH_RESULT }}${dataset}/${dataset}_tables.json 2>&1
          fi
        done
        
        echo "Dataset structure extraction completed"
    - id: upload-files
      name: Upload Files to GitHub
      if: success()
      run: |
        # Upload files to GitHub
        echo "Uploading files to the repository..."
        git config --global user.name "${{ secrets.KAOS_BOT_NAME }}"
        git config --global user.email "${{ secrets.KAOS_BOT_EMAIL }}"
        echo "Git pull ..."
        git pull
        echo "Git add * ..."
        git add *
        echo "Git add ${{ env.KAOS_PATH_RESULT }}* ..."
        git add ${{ env.KAOS_PATH_RESULT }}*
        echo "Git add ${{ env.KAOS_PATH_OUTPUT }}* ..."
        git add ${{ env.KAOS_PATH_OUTPUT }}*
        echo "Si existe el fichero lo borro ..."
        if [ -f "gha-creds*" ]; then git rm gha-creds*; fi
        echo " Git Commit ..."
        git commit -m "[Ka0S] BigQuery Structure Extraction"
        echo "Git push ..."
        git push

  handle-success:
      runs-on: self-hosted
      needs: [job-core]
      if: ${{ success() }}
      steps:
        - id: repo
          name: Checkout code
          if: ${{ always() }}
          uses: actions/checkout@v4
          with:
            fetch-depth: 0
            token: ${{ secrets.KAOS_REPO_TOKEN }}
        - id: end-handle
          name: Finaliza el workflow
          run: |
            echo "Handle Success please check ${{ env.KAOS_CODE }}"

  handle_failure:
      runs-on: self-hosted
      needs: [job-core, handle-success]
      if: ${{ failure() }} 
      steps:
        - id: repo
          name: Checkout code
          if: ${{ always() }}
          uses: actions/checkout@v4
          with:
            fetch-depth: 0
            token: ${{ secrets.KAOS_REPO_TOKEN }}
        - id: end-handle
          name: Finaliza el workflow
          run: |
            echo "Handle Failure please check ${{ env.KAOS_CODE }}"

  end-workflow:
      runs-on: self-hosted
      needs: [job-core, handle-success, handle_failure]
      if: ${{ always() && !contains(github.event.head_commit.message, '[Ka0S] ') }} 
      env:
          GH_TOKEN: ${{ secrets.KAOS_REPO_TOKEN }}
      steps:
        - id: repo
          name: Checkout code
          if: ${{ always() }}
          uses: actions/checkout@v4
          with:
            fetch-depth: 0
            token: ${{ secrets.KAOS_REPO_TOKEN }}
        - id: end-process
          name: Finaliza el workflow
          run: |
            echo "End process"
            echo "Se finaliza Ka0s ${{ env.KAOS_CODE }}"
            gh workflow run inspector.yml --ref ${{ env.KAOS_REF_BRANCH }} -f kaos-issue-id= -f kaos-workflow-id="${{ env.KAOS_CODE }}" -f kaos-user-start=""
